{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "329860ad-a3af-47b6-9905-7fd133a2d6d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "from urllib.parse import urlparse,parse_qs\n",
    "from os.path import splitext, basename, dirname\n",
    "from urllib.parse import urlparse,parse_qs\n",
    "from operator import methodcaller as call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f8de702c-72aa-4495-be90-dcb0279c4049",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataframe():\n",
    "    #read panel dataset and drop beacons without cookies\n",
    "    panel_df=pd.read_json(\"data/panel_dataset.json.gz\", convert_dates=[\"date\"], compression=\"gzip\", lines=True)\n",
    "    panel_df.loc[panel_df[\"actor_cookie\"]==\"NA\",\"actor_cookie\"]=\"\"\n",
    "    panel_df = panel_df[panel_df.actor_cookie != \"\"]\n",
    "\n",
    "    #split panel into sub fields\n",
    "    panel_df[\"panel_prot\"]=panel_df[\"panel_url\"].apply(urlparse).apply(lambda x: x[0])\n",
    "    panel_df[\"panel_path\"]=panel_df[\"panel_url\"].apply(urlparse).apply(lambda x: (dirname(x[2]) if (splitext(x[2])[1] != '') else x[2]))\n",
    "    panel_df[\"panel_ext\"]=panel_df[\"panel_url\"].apply(urlparse).apply(lambda x: (basename(x[2]) if (splitext(x[2])[1] != '') else \"\"))\n",
    "    panel_df[\"panel_id\"]=panel_df[\"panel_domain\"].str.lstrip(\"www.\")+panel_df[\"panel_path\"].str.rstrip(\"/\").str.replace(\"bots\",\"\").str.replace(\"dashboard\",\"\") # trim trailing /\n",
    "\n",
    "    #load UA subfields\n",
    "    uadf=pd.read_json(\"data/parsed_user_agents.json.gz\", compression=\"gzip\", lines=True)\n",
    "    panel_df=panel_df.merge(uadf,how=\"left\",on=\"actor_ua\").fillna(\"\")\n",
    "    \n",
    "    return panel_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "01d67c8a-3eb1-455a-9b09-6e99920a19de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_ver(ver=\"\"):  \n",
    "    \"\"\" Function to parse browser version string into integer for comparision\n",
    "        :return: an integer representation of browser version. \n",
    "    \"\"\"\n",
    "    \n",
    "    ver_numeric=[]\n",
    "    for ver_i in ver.split(\".\"):\n",
    "        if ver_i.isnumeric():\n",
    "            ver_numeric.append(int(ver_i))\n",
    "        else:\n",
    "            ver_numeric.append(ver_i)\n",
    "    return ver_numeric\n",
    "\n",
    "def merge_panel_cookies(dataframe):\n",
    "    \"\"\" Function to merge cookies into distinct device IDs.\n",
    "        :dataframe: Pandas dataframe containing panel beacons with columns:[date,cookie,user_agent_operating_system,user_agent_browser,user_agent_browser_version]\n",
    "        :return: a dictionary of merged cookies (device ids) and their respective merged cookies.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Initialize variables\n",
    "    df=dataframe.copy()\n",
    "    cluster_id=0\n",
    "    merged_cc={}\n",
    "    cluster_group={}\n",
    "    collision=[]\n",
    "    all_cookies = set(df.actor_cookie.unique())\n",
    "    merged_cookies = set()\n",
    "    processed_cookie_clusters = set()\n",
    "    device_id=0\n",
    "    merged_devices = {}\n",
    "    \n",
    "    # Create graph for calculated connected components of panels and cookies\n",
    "    df.loc[df.actor_cookie!=\"\",\"vtheta_label\"]=\"o>\"+df[df.actor_cookie!=\"\"].actor_cookie\n",
    "    df.loc[df.actor_cookie!=\"\",\"vpi_label\"]=\"p>\"+df[df.actor_cookie!=\"\"].panel_id\n",
    "    c2pG = nx.Graph()\n",
    "    c2pG.add_nodes_from(df.loc[df.actor_cookie!=\"\",\"vtheta_label\"].unique())\n",
    "    c2pG.add_nodes_from(df.loc[df.actor_cookie!=\"\",\"vpi_label\"].unique())\n",
    "    c2pG.add_edges_from(df.loc[df.actor_cookie!=\"\",[\"vtheta_label\",\"vpi_label\"]].drop_duplicates().values)\n",
    "\n",
    "    # merging algorithm according to A. Dasgupta :“Overcoming browser cookie churn with clustering”\n",
    "    for c in sorted(nx.connected_components(c2pG), key=len, reverse=True)[:]:\n",
    "        # For each connected component of panels and cookies looks for potential cookies that can be merged\n",
    "\n",
    "        cc=c2pG.subgraph(list(c)).copy()\n",
    "        op=set(filter(call('startswith', 'o>'),filter(lambda x: x == x , c)))\n",
    "        pn=set(filter(call('startswith', 'p>'),c))\n",
    "\n",
    "        #Skip components with only one cookie\n",
    "        if len(op)>1:\n",
    "            panels=list(map( lambda x: x[2:],pn)) # get list of panel ids and remove the p> chars\n",
    "            df_l1=df[(df.actor_cookie!=\"\") & ((df.browser!=\"\") | (df.os!=\"\")) & (df.panel_path!=\"/\")].loc[df.panel_id.isin(panels),[\"date\",\"actor_cookie\",\"os\",\"browser\",\"browser_ver\"]]\n",
    "\n",
    "            # For each cookie in component calculate aggregate stats\n",
    "            if len(df_l1) != 0:\n",
    "                df_l1=df_l1.groupby(\n",
    "                    \"actor_cookie\",as_index=False).agg(\n",
    "                    lifespan=(\"date\",lambda x: pd.Interval(x.min(),x.max(),closed=\"neither\")),\n",
    "                    os_count=(\"os\", \"nunique\"),\n",
    "                    bw_count=(\"browser\", \"nunique\"),\n",
    "                    bwv_count=(\"browser_ver\", \"nunique\"),\n",
    "                    os=(\"os\",lambda x: x.values.all()),\n",
    "                    browser=(\"browser\",lambda x: x.values.all()),\n",
    "                    browser_ver=(\"browser_ver\",lambda x: x.values.all())).sort_values(\"lifespan\")\n",
    "\n",
    "        cluster_list=[]\n",
    "        merged_count=0\n",
    "        m=0\n",
    "        for name, group in df_l1.groupby([\"os\",\"browser\"]):\n",
    "            #Group by device components(operating system and browser) and look for potential merging candidates\n",
    "            \n",
    "            collision_count=0\n",
    "            cluster_key=\"{}_{}\".format(name[0].strip().lower(),name[1].strip().lower().replace(\" \",\"_\"))\n",
    "            clusters={} # initialize cluster\n",
    "            merged_count+=m\n",
    "            m=0\n",
    "            merged_j=[] # track all the j_th elements that have been merged\n",
    "            for i in range(0,len(group.index)):\n",
    "                actor_i_cookie=group.iloc[i].actor_cookie\n",
    "                actor_i_bwv=group.iloc[i].browser_ver\n",
    "                actor_i_interval=group.iloc[i].lifespan\n",
    "                actor_i_panels=df[df.actor_cookie==group.iloc[i].actor_cookie].panel_id.unique().tolist()\n",
    "                skip_merge=False # already in a cluster, skip merging\n",
    "\n",
    "                # check if already merged\n",
    "                for k,v in clusters.items():\n",
    "                    if actor_i_cookie in v.keys():\n",
    "                        skip_merge=True\n",
    "                        break\n",
    "\n",
    "                if skip_merge:\n",
    "                    continue\n",
    "\n",
    "                clusters[m]={actor_i_cookie:{\n",
    "                    #\"cookie\":actor_i_cookie,\n",
    "                    \"interval\":actor_i_interval,\n",
    "                    \"panels\":actor_i_panels,\n",
    "                    \"browser_ver\":actor_i_bwv}}\n",
    "                m+=1 # latest cluster id\n",
    "\n",
    "\n",
    "                for j in range(i+1,len(group.index)):\n",
    "                    # find the first non-overlaping cluster to merge cookie\n",
    "                    cluster_found=False\n",
    "                    actor_j_cookie=group.iloc[j].actor_cookie\n",
    "                    actor_j_bwv=group.iloc[j].browser_ver\n",
    "                    actor_j_interval=group.iloc[j].lifespan\n",
    "                    actor_j_panels=df[df.actor_cookie==group.iloc[j].actor_cookie].panel_id.unique().tolist()\n",
    "                    for k,v in clusters.items(): # iterate through clusters\n",
    "\n",
    "                        # create interval to check\n",
    "                        interval_list=[]\n",
    "                        panel_list=[]\n",
    "                        lifespan_list=[]\n",
    "                        browser_ver_list=[]\n",
    "\n",
    "                        # has cookie_j already been merged?\n",
    "                        #if actor_j_cookie in v.keys():\n",
    "                        #    cluster_found=True\n",
    "\n",
    "                        for k2,v2 in v.items(): # iterate through cookies\n",
    "                            for k3,v3 in v2.items(): # iterate through interval/panels\n",
    "                                if k3==\"interval\":\n",
    "                                    interval_list.append(v3)\n",
    "                                    lifespan_list.append(v3.length.seconds)\n",
    "                                elif k3==\"panels\":\n",
    "                                    panel_list.append(v3)\n",
    "                                elif k3==\"browser_ver\":\n",
    "                                    browser_ver_list.append(v3)\n",
    "\n",
    "                        panel_list=set(panel_list[0])\n",
    "\n",
    "                        cookie_interval=pd.arrays.IntervalArray(interval_list)\n",
    "\n",
    "                        # compare version number make sure j is >= i\n",
    "                        ver_j_numeric=parse_ver(actor_j_bwv)\n",
    "\n",
    "                        jlei=True # flag j>= for ALL of i by default we assume it is true\n",
    "                        for actor_i_bwv in browser_ver_list:\n",
    "                            ver_i_numeric=parse_ver(actor_i_bwv)\n",
    "                            for i in range(0, min(len(ver_i_numeric),len(ver_j_numeric))):\n",
    "                                if ver_j_numeric[i]<ver_i_numeric[i]:\n",
    "                                    jlei=False\n",
    "\n",
    "                        if not cookie_interval.overlaps(actor_j_interval).any() and len(set(actor_j_panels).intersection(panel_list))>0 and jlei:\n",
    "                            if not (j in merged_j):# cluster_found:\n",
    "                                clusters[k].update({actor_j_cookie:{\n",
    "                                    \"interval\": actor_j_interval,\n",
    "                                    \"panels\": actor_j_panels,\n",
    "                                    \"browser_ver\":actor_j_bwv}})\n",
    "                                merged_j.append(j)\n",
    "                                #cluster_found=True\n",
    "                            else:\n",
    "                                collision.append({\"compid\":cluster_id,\n",
    "                                                  \"total_dev\":len(op),\n",
    "                                                  \"os_browser\":cluster_key,\n",
    "                                                  \"group_size\":len(group),\n",
    "                                                  \"cookie_i\":actor_i_cookie,\n",
    "                                                  \"cookie_j\":actor_j_cookie})\n",
    "                                collision_count+=1\n",
    "\n",
    "            cluster_list.append({\"before_merge\":len(group.index),\"after_merged\":m,\"os_browser\":cluster_key,\"clusters\":clusters})\n",
    "            \n",
    "            # Start building the final merged_devices dictionary with the processed cookies (merged or not merged)\n",
    "            for cluster_items in clusters.items():\n",
    "                # These cookies are now one device \n",
    "                joined_cookies = \",\".join(list(cluster_items[1].keys()))\n",
    "                if joined_cookies not in processed_cookie_clusters:\n",
    "                    processed_cookie_clusters.add(joined_cookies)\n",
    "                    merged_devices[device_id] = joined_cookies\n",
    "                    device_id += 1\n",
    "                    for cookie in list(cluster_items[1].keys()):\n",
    "                        merged_cookies.add(cookie)\n",
    "\n",
    "        merged_cc[cluster_id]=cluster_list\n",
    "        cluster_id+=1\n",
    "\n",
    "    # For all the panels and cookies that had no potential merging candidates, assign them a new device id\n",
    "    island_cookies = all_cookies.difference(merged_cookies)\n",
    "    for island_cookie in sorted(island_cookies):\n",
    "        merged_devices[device_id] = island_cookie\n",
    "        device_id += 1\n",
    "\n",
    "    return merged_devices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "48979b95-d807-4331-9b0e-9c0860eff705",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "560 cookies merged to 214 device IDs\n"
     ]
    }
   ],
   "source": [
    "# Load panel dataset\n",
    "df = load_dataframe()\n",
    "# Apply the cookie merging algorithm and get the device id to cookies dictionary\n",
    "final_merged_devices = merge_panel_cookies(df)\n",
    "\n",
    "# Assign each cookie their respective device id based on the merged cookies dictionary\n",
    "df_merged=df.copy()\n",
    "df_merged[\"operator_device_id\"]=-1\n",
    "merged_cookies_num = 0\n",
    "merged_devices_num = 0\n",
    "for device_id, device_cookies in final_merged_devices.items():\n",
    "    cookies=device_cookies.split(\",\")\n",
    "    if len(cookies) > 1 :\n",
    "        merged_cookies_num += len(cookies)\n",
    "        merged_devices_num += 1\n",
    "    df_merged.loc[df_merged.actor_cookie.isin(cookies),\"operator_device_id\"]=device_id\n",
    "\n",
    "print(\"%s cookies merged to %s device IDs\" % (merged_cookies_num,merged_devices_num))\n",
    "\n",
    "#Write the final dataframe to JSON\n",
    "df_merged.to_json('panel_dataset_cookie_merged_final.json.gz', compression=\"gzip\", orient=\"records\", lines=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
